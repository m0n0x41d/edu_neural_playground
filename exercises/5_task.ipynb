{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74107f1d-c1ca-431c-843b-28ac821c6d91",
   "metadata": {},
   "source": [
    "Here is the training of model to recognize handwritten digits using the MNIST dataset. \n",
    "It is very similar to previous task models, becuase neural network working with raw bytes, and it is really cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a76f03-e4f4-47d7-a6c5-dd0297e15960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "60000\n",
      "10000\n",
      "0\n",
      "1\n",
      "OrderedDict({'0.weight': tensor([[-0.0089, -0.0141, -0.0111,  ..., -0.0103,  0.0233,  0.0006],\n",
      "        [-0.0191,  0.0107, -0.0324,  ...,  0.0117, -0.0119,  0.0166],\n",
      "        [-0.0314,  0.0271, -0.0139,  ...,  0.0126, -0.0114, -0.0041],\n",
      "        ...,\n",
      "        [-0.0137, -0.0068,  0.0204,  ...,  0.0154,  0.0129,  0.0216],\n",
      "        [ 0.0353, -0.0192, -0.0110,  ...,  0.0341,  0.0288,  0.0015],\n",
      "        [-0.0207,  0.0344, -0.0196,  ..., -0.0203,  0.0045, -0.0102]]), '0.bias': tensor([-1.2590e+00, -1.2245e-01, -8.3743e-01, -9.3340e-02, -9.0592e-02,\n",
      "        -6.1734e-02, -1.1173e+00, -3.0627e-01, -1.8500e-01, -2.9571e-01,\n",
      "        -1.4194e-01, -3.9010e-01, -4.5114e-02, -3.7641e-01, -5.0299e-01,\n",
      "        -3.3815e-01, -6.7501e-02, -5.3981e-01, -5.8186e-02, -2.9449e-02,\n",
      "        -7.2155e-02, -1.3848e+00, -3.6542e-02, -1.6157e-01, -6.5552e-02,\n",
      "        -7.1398e-02, -1.9690e+00, -2.9253e-02, -3.3262e-01, -5.5732e-02,\n",
      "        -7.6555e-02, -2.7116e-01, -1.1832e-01, -1.5092e+00, -6.1777e-02,\n",
      "        -2.7249e-01, -3.6993e-02, -7.0787e-02, -9.4586e-02, -4.9179e-02,\n",
      "        -1.9397e-01, -1.5598e+00, -7.1840e-02, -6.5431e-02, -9.4644e-02,\n",
      "        -1.2586e-01, -1.5206e-01, -9.7006e-02, -5.8418e-02, -3.5030e-01,\n",
      "        -8.1759e-01, -4.4349e-02, -2.2385e-01, -5.2453e-02, -6.0122e-02,\n",
      "        -7.3051e-02, -9.4417e-02, -6.9226e-02, -7.6621e-02, -7.8048e-02,\n",
      "        -1.2379e+00, -3.7988e-02, -8.4189e-02, -7.0898e-02, -5.6899e-01,\n",
      "        -5.5793e-02, -7.4740e-01, -4.4577e-02, -3.5377e-02, -8.4344e-02,\n",
      "        -8.2930e-02, -2.6546e-01, -8.9614e-02, -8.5374e-02, -1.4904e-01,\n",
      "         8.2011e-02, -8.4564e-02, -9.3706e-02, -1.9208e-01, -7.6549e-02,\n",
      "        -8.2220e-02, -1.1158e-01, -4.2914e-02, -4.1538e-01, -7.1710e-02,\n",
      "        -8.3122e-02, -8.0083e-02, -1.2187e-01, -1.4525e-01, -7.2365e-01,\n",
      "        -4.0844e-01, -3.4653e-01, -3.7385e-02, -4.9587e-02, -1.0098e-01,\n",
      "        -8.4319e-02, -3.2819e-02, -1.4566e-01, -6.7367e-02, -5.7653e-01,\n",
      "        -1.0882e-01, -2.0852e+00, -6.8499e-02, -2.6702e-01, -3.0983e-02,\n",
      "        -4.8596e-02, -1.5930e-02, -7.9690e-01, -5.2059e-01, -1.1909e-01,\n",
      "        -6.3903e-03, -3.0305e+00, -4.8509e-01, -6.0079e-02, -2.5764e-02,\n",
      "        -9.0423e-02, -6.7609e-02, -1.0665e+00, -8.6134e-02, -5.1481e-02,\n",
      "        -2.6754e-02, -7.3613e-01, -2.2286e-01, -9.1924e-02, -4.1876e-01,\n",
      "        -4.3348e-02, -2.7960e-02, -1.1182e-01, -5.7999e-02, -8.6849e-02,\n",
      "        -7.2997e-01, -9.3966e-02, -5.7147e-02, -1.1199e-01, -4.9687e-02,\n",
      "        -5.1873e-02, -1.9594e+00, -8.5753e-02, -2.5022e-02, -6.4264e-02,\n",
      "        -6.9703e-01, -8.0128e-02, -1.1063e-01, -1.6573e+00, -2.3774e-01,\n",
      "        -5.6118e-02, -4.6797e-01, -9.9114e-02, -3.2367e-01, -2.3612e-01,\n",
      "        -2.7700e-01, -5.1515e-02, -5.3657e-02, -6.2172e-02, -5.2403e-02,\n",
      "        -1.9344e-01, -7.5982e-02, -3.9320e-02, -6.0619e-01, -1.5434e+00,\n",
      "        -8.5726e-02, -3.3561e+00, -9.0319e-02, -8.2920e-02, -5.8648e-01,\n",
      "        -2.1018e+00, -4.6599e-02, -1.2153e+00, -4.4448e-01, -2.8925e-01,\n",
      "        -6.7096e-02, -1.1374e-01, -9.9293e-02, -2.4907e+00, -1.1972e-01,\n",
      "        -6.6122e-02, -3.5059e-02, -4.5109e-02, -1.4352e-01, -1.8360e-01,\n",
      "        -7.0065e-02, -1.7707e-01, -6.2591e-02, -7.7883e-02, -2.7022e-01,\n",
      "        -8.1698e-02, -4.5988e-02, -2.7010e-02, -6.5697e-02, -7.8250e-02,\n",
      "        -1.7039e-01, -2.1286e-01, -3.8856e-01, -8.5832e-02,  4.5941e-02,\n",
      "        -4.0379e-01,  9.7155e-02, -1.2002e+00, -6.0005e-01, -5.9138e-01,\n",
      "        -6.8018e-02, -1.4403e-01, -8.1196e-01, -4.6699e-02, -3.2469e-02,\n",
      "        -1.6929e+00, -9.0470e-02, -4.7798e-02, -2.5176e-02, -7.3715e-01,\n",
      "        -3.7067e-02, -3.8371e-02, -4.9896e-01, -7.3900e-02, -5.5983e-02,\n",
      "        -1.5352e-01, -8.1224e-02, -1.4981e-01, -6.2650e-02, -1.6433e-01,\n",
      "        -8.5272e-02, -2.0429e-01, -2.2987e-01, -4.3673e-01, -1.7443e-01,\n",
      "        -8.8210e-02, -1.1404e+00, -1.0040e-01, -3.1715e-02, -2.1280e-02,\n",
      "        -3.1107e-01, -1.4692e-02, -7.9016e-02, -5.6955e-01, -1.6647e-01,\n",
      "        -4.8358e-02, -9.2939e-02, -2.0980e+00, -3.7437e-01, -8.1575e-02,\n",
      "        -7.7444e-02, -2.2442e-01, -7.4944e-02, -1.2273e-01, -9.1180e-02,\n",
      "        -6.0907e-02, -8.6304e-02, -2.8878e-01, -7.6767e-02, -4.4009e-02,\n",
      "        -3.7867e-02, -1.6354e+00, -3.7467e-01, -3.0172e-02, -1.5278e-01,\n",
      "        -8.9922e-02, -9.2036e-02, -4.8455e-01, -3.3630e-01, -2.6030e-01,\n",
      "        -9.4675e-02, -9.6749e-02, -1.7981e-02, -6.0944e-02, -2.5700e-02,\n",
      "        -9.7912e-01, -1.0405e-01, -5.4799e-02, -6.1699e-02, -6.9475e-02,\n",
      "        -1.3407e-01, -4.1297e-01, -4.2805e-01, -2.4707e-01, -7.8182e-02,\n",
      "        -9.6691e-02, -1.8779e+00, -1.1907e-01, -1.4839e-01, -8.1722e-02,\n",
      "        -7.7515e-02, -6.1623e-01, -1.0989e+00, -1.2884e-01, -1.0089e-01,\n",
      "         1.9806e-01, -1.3370e+00, -3.9168e-02, -1.5288e-01, -9.5207e-02,\n",
      "        -8.9480e-02,  7.2592e-03, -4.0418e-02, -7.4783e-01, -2.2926e-01,\n",
      "        -9.3833e-02, -6.0873e-02, -5.3852e-01, -1.4293e-02, -3.9735e-01,\n",
      "        -5.4850e-02, -5.2061e-02, -1.0019e-01, -8.6951e-02, -6.7055e-01,\n",
      "        -2.0550e-02, -8.9361e-01, -5.6971e-01, -1.9446e-01, -1.2780e-01,\n",
      "        -2.9926e-02, -3.1812e-02, -5.4832e-02, -6.7029e-02, -2.0766e-01,\n",
      "        -2.7550e-02, -3.0411e-02, -4.6292e-01, -5.7340e-02, -1.9709e+00,\n",
      "        -4.9083e-02, -7.9785e-02, -2.1292e-01, -6.7185e-02, -2.0403e-01,\n",
      "        -9.9162e-02, -7.5199e-02, -4.3878e-02, -2.5356e-01, -5.5547e-02,\n",
      "        -7.9327e-02, -2.0328e-01, -3.3042e-01, -8.4111e-02, -1.6302e+00,\n",
      "        -4.3770e-02, -7.1547e-02, -7.0480e-02, -6.4258e-02, -2.2846e-01,\n",
      "        -6.9295e-02, -4.4864e-02, -7.6238e-02, -3.1312e-02, -3.0205e-01,\n",
      "        -3.4529e-02, -4.0515e-02, -7.8784e-02, -7.1093e-01, -7.8346e-01,\n",
      "        -5.5496e-02, -4.6512e-01, -7.1851e-02, -1.6142e+00, -6.4408e-02,\n",
      "        -1.6115e-01, -9.8696e-01, -1.3070e-01, -1.4455e-01, -2.9450e-01,\n",
      "        -3.5574e-02, -9.2048e-02, -2.0131e+00, -6.9519e-02, -7.9410e-02,\n",
      "        -8.7834e-02, -6.8919e-02, -5.9110e-01, -1.0966e-01, -8.4130e-02,\n",
      "        -5.4175e-02, -1.0236e-01, -7.5110e-02, -8.9965e-02, -5.4993e-01,\n",
      "        -3.6938e-02, -1.2267e-03, -3.6712e-01, -2.5224e-02, -3.1864e-01,\n",
      "        -9.6644e-02, -7.4407e-02, -3.7090e-02, -1.1069e-01, -5.1186e-02,\n",
      "        -4.4699e-01, -6.7676e-02, -3.2729e-01, -1.2557e-01, -5.6755e-02,\n",
      "        -1.0345e+00, -4.0660e-02, -4.4188e-02, -4.1069e-02, -8.3139e-01,\n",
      "        -3.5362e-02, -8.2075e-02, -1.3970e+00, -1.9966e-02, -1.5697e-01,\n",
      "        -3.0125e-02, -5.6572e-02, -4.9703e-01, -4.3903e-01, -5.4763e-02,\n",
      "        -2.3088e-01, -6.4777e-01, -2.5881e-02, -3.0653e-01, -2.9400e-02,\n",
      "        -5.1867e-02, -4.6667e-02, -8.7520e-02, -1.0378e-01, -4.7214e-01,\n",
      "        -5.8430e-02, -6.5888e-02, -1.0680e-01, -7.9275e-02, -6.8213e-02,\n",
      "        -1.1792e-01, -5.4270e-02, -4.7418e-01, -4.6225e-02, -9.7829e-02,\n",
      "        -6.5706e-02, -6.7357e-02, -2.2360e-01, -7.8631e-02, -4.4114e-02,\n",
      "        -6.8943e-02, -1.0572e+00, -1.0901e-01, -5.3896e-01, -4.8836e-02,\n",
      "        -2.7711e-02, -6.7123e-02, -1.2644e-01, -4.6711e-01, -5.8497e-02,\n",
      "        -2.3498e-01, -9.3346e-02, -5.2384e-01, -5.8118e-01, -4.4431e-02,\n",
      "        -7.2320e-01, -5.9428e-02, -3.6183e-02, -7.5593e-02, -1.6124e-01,\n",
      "        -3.4134e-02, -1.6627e+00, -4.5342e-02, -3.6988e-01, -1.0974e+00,\n",
      "        -1.3838e+00, -3.0539e-01, -6.9009e-02, -2.5475e-01, -5.8490e-02,\n",
      "        -5.9322e-02, -8.0145e-02, -7.9515e-02, -8.6249e-02, -5.4333e-02,\n",
      "        -1.6923e-01, -3.0794e-01, -1.6141e+00, -1.0553e-01, -2.1112e-01,\n",
      "        -1.6376e+00, -2.4475e-02, -4.0298e-01, -3.8889e-02, -5.9323e-01,\n",
      "        -3.1022e-02, -8.9451e-02, -8.1205e-02, -7.9057e-02, -6.3902e-01,\n",
      "        -3.1226e+00, -4.7186e-01, -8.5398e-02, -1.8639e+00, -5.6572e-02,\n",
      "        -1.6881e+00, -9.8760e-01, -7.4141e-01, -6.2618e-02, -4.9451e-02,\n",
      "        -3.5071e-01, -2.0667e-01, -8.1647e-02, -4.6215e-02, -1.7261e-01,\n",
      "        -2.0981e-01, -4.0718e-01, -3.6938e-01, -1.0919e-01, -2.4667e-01]), '2.weight': tensor([[ 2.5994e-01,  2.0245e-03, -7.0785e-01,  ...,  3.3045e-01,\n",
      "         -6.8884e-02,  2.6495e-01],\n",
      "        [-2.1698e+00, -4.4672e-02, -1.3072e+00,  ..., -2.2228e-02,\n",
      "         -3.9370e-02, -5.2837e-01],\n",
      "        [-1.5382e+00, -1.3800e-01,  3.7607e-02,  ...,  9.1485e-03,\n",
      "          4.3735e-02, -5.0202e-01],\n",
      "        ...,\n",
      "        [ 7.9764e-02, -1.6134e-01, -4.0178e-01,  ..., -3.3470e-02,\n",
      "         -7.1661e-03, -2.3242e-01],\n",
      "        [-2.9433e+00, -9.0858e-02, -1.2368e-01,  ..., -9.5542e-02,\n",
      "          1.8145e-03, -1.0040e+00],\n",
      "        [-1.0278e+00, -3.4223e-02, -7.8975e-01,  ...,  1.6842e-02,\n",
      "         -3.8130e-02, -1.1247e+00]]), '2.bias': tensor([ 0.0835, -1.3496, -0.1140, -0.1120, -0.6632, -0.3078, -0.5281, -1.4564,\n",
      "         2.2883,  0.3435])})\n",
      "0.4808143675327301\n",
      "Accuracy: 92.18 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "\n",
    "input_size = 28*28  # Image size in pixels\n",
    "hidden_size = 500  # Number of neurons in the hidden layer\n",
    "num_classes = 10  # Number of classes to recognize (10 digits)\n",
    "n_epochs = 2  # Number of epochs\n",
    "batch_size = 4  # Mini-batch size of input data\n",
    "lr = 0.01  # Learning rate\n",
    "\n",
    "\n",
    "# Lets download dataset\n",
    "mnist_trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Training data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_trainset, batch_size=batch_size, shuffle=True)  \n",
    "# Test data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_testset, batch_size=batch_size, shuffle=False)  \n",
    "\n",
    "# Init device as usual\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# OUr standard \"training step\" func, alike we used before\n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        loss = train_step(images, labels)\n",
    "    print(epoch)\n",
    "\n",
    "print(model.state_dict())\n",
    "print(loss)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ba92e-d5cb-451e-bb30-0d374e5df47a",
   "metadata": {},
   "source": [
    "It is really good for two epochs to have ~90% accuracy! Running code snippet above we should get at the end something like:\n",
    "```\n",
    "0.4808143675327301\n",
    "Accuracy: 92.18 %\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Well, lets improve it somehow.\n",
    "Lets define some сhallenges we can throw at ourselves.\n",
    "1. We could try to improve the accuracy of our model, by playng with these things:\n",
    "- Increase the number of epochs.\n",
    "- Increase the number of neurons.\n",
    "- Add new hidden layers.\n",
    "- Change the mini-batch size.\n",
    "\n",
    "2. And also lets try to find a way to visualize the model’s performance on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db81cb4-e40a-42e8-b3c0-340935871d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2660\n",
      "Epoch [2/5], Loss: 0.1090\n",
      "Epoch [3/5], Loss: 0.2167\n",
      "Epoch [4/5], Loss: 0.0704\n",
      "Epoch [5/5], Loss: 0.0183\n",
      "OrderedDict({'0.weight': tensor([[-0.0230,  0.0012,  0.0223,  ..., -0.0311,  0.0031,  0.0296],\n",
      "        [ 0.0332, -0.0216, -0.0337,  ...,  0.0351, -0.0039, -0.0127],\n",
      "        [ 0.0053, -0.0098, -0.0282,  ..., -0.0049, -0.0145,  0.0188],\n",
      "        ...,\n",
      "        [ 0.0126, -0.0135,  0.0235,  ..., -0.0308,  0.0354, -0.0079],\n",
      "        [-0.0028, -0.0032,  0.0217,  ..., -0.0353, -0.0010, -0.0015],\n",
      "        [ 0.0217, -0.0312,  0.0089,  ..., -0.0137,  0.0163,  0.0135]]), '0.bias': tensor([ 0.0743, -0.1348,  0.0040, -0.0557,  0.0136, -0.0591,  0.0211, -0.0272,\n",
      "         0.0647, -0.1200,  0.0223,  0.0196, -0.0253, -0.0975, -0.0706, -0.0680,\n",
      "         0.0129,  0.1218, -0.0638, -0.0372, -0.0295,  0.0613,  0.0047,  0.0461,\n",
      "        -0.0768, -0.0544,  0.0153, -0.0668,  0.0500, -0.0770, -0.0546, -0.0364,\n",
      "        -0.0355, -0.0706, -0.0323,  0.0116, -0.0093,  0.0352, -0.0265, -0.0048,\n",
      "         0.0155, -0.0956,  0.0303,  0.0239, -0.0320, -0.0402,  0.0628,  0.0173,\n",
      "         0.0504, -0.0744, -0.0442,  0.0206, -0.0779, -0.0094,  0.0107,  0.1308,\n",
      "        -0.0575, -0.0034,  0.0315, -0.0510, -0.0391,  0.0184,  0.0524, -0.0757,\n",
      "         0.0293, -0.0283,  0.0372,  0.0056, -0.1355,  0.0392, -0.0154,  0.0505,\n",
      "         0.0122,  0.0177,  0.0013, -0.0021, -0.1086,  0.0428, -0.0480, -0.0414,\n",
      "        -0.0832,  0.0679, -0.0251, -0.0953, -0.0424, -0.0537, -0.0620,  0.0173,\n",
      "        -0.0167,  0.0446, -0.0695, -0.0893, -0.1020, -0.0524, -0.0342, -0.0157,\n",
      "        -0.0167, -0.0794,  0.0874,  0.0049, -0.0207, -0.0877,  0.0565, -0.0193,\n",
      "         0.0307, -0.0561, -0.0428,  0.0482, -0.0217,  0.0514, -0.0572, -0.0187,\n",
      "         0.0347, -0.0069,  0.0894,  0.0129,  0.0141,  0.0733,  0.0846,  0.0508,\n",
      "        -0.0595, -0.0677, -0.0470, -0.0144,  0.0738, -0.0082,  0.0080, -0.0127,\n",
      "         0.0385,  0.0824, -0.0481, -0.0757, -0.0841,  0.0557,  0.0320, -0.0110,\n",
      "        -0.0610, -0.0494,  0.0013,  0.0221, -0.0154,  0.0173,  0.0135, -0.0610,\n",
      "         0.0809, -0.0266, -0.0016,  0.0590,  0.0490,  0.0004,  0.0628,  0.0081,\n",
      "        -0.0176,  0.0725, -0.0557, -0.0764, -0.0379, -0.0236,  0.0261,  0.0661,\n",
      "        -0.0568, -0.0693,  0.0208, -0.0442, -0.0153,  0.0209, -0.0141, -0.0057,\n",
      "         0.0506,  0.0066, -0.0042,  0.0109,  0.0431,  0.0344, -0.0218, -0.0030,\n",
      "        -0.0906, -0.0847, -0.0315, -0.0348, -0.1061,  0.0968, -0.0406, -0.0412,\n",
      "        -0.0299, -0.0432, -0.0111, -0.0454, -0.0845,  0.0249, -0.0126, -0.0125,\n",
      "        -0.0191, -0.0450,  0.0123, -0.0356,  0.0306, -0.0500,  0.0117,  0.0534,\n",
      "         0.0068, -0.0585,  0.0152,  0.0038,  0.0405, -0.0407, -0.0475, -0.0926,\n",
      "         0.0226, -0.0331,  0.0365, -0.0130,  0.0054,  0.0086, -0.0479, -0.1087,\n",
      "        -0.0091, -0.0056,  0.0121,  0.0557,  0.0262,  0.0076,  0.0798, -0.0380,\n",
      "         0.0285,  0.0291, -0.0684,  0.0095, -0.0404, -0.0356, -0.0066, -0.0858,\n",
      "        -0.0076,  0.0820, -0.0052, -0.0465, -0.0397, -0.0166, -0.0260, -0.0104,\n",
      "        -0.0503, -0.0882,  0.0348,  0.0092, -0.0089, -0.0137,  0.1123,  0.0314,\n",
      "        -0.0295,  0.0210,  0.0370, -0.0763, -0.0501, -0.0807,  0.0030, -0.0300,\n",
      "        -0.0784, -0.1067,  0.0070, -0.0328, -0.0485, -0.0599, -0.0538, -0.0300,\n",
      "         0.0167, -0.0416, -0.0410,  0.0885, -0.0584, -0.0046,  0.1287, -0.0451,\n",
      "         0.0080,  0.0609, -0.0507, -0.0058, -0.0524,  0.0283, -0.0026, -0.0115,\n",
      "        -0.0352, -0.0685, -0.0184, -0.0244, -0.0553,  0.0946,  0.1306, -0.0205,\n",
      "        -0.0244, -0.0810, -0.0591,  0.0171, -0.0167, -0.0408,  0.0346,  0.0233,\n",
      "        -0.0181, -0.0091,  0.0233, -0.0369,  0.0736,  0.0208, -0.0366,  0.0708,\n",
      "        -0.0120,  0.0172,  0.0053, -0.0428,  0.0672, -0.0378, -0.0781, -0.0561,\n",
      "        -0.0792, -0.0217, -0.0973, -0.0449, -0.0168,  0.0322,  0.0553, -0.0280,\n",
      "         0.0388,  0.0107, -0.0517, -0.0922,  0.0131, -0.0465, -0.0245, -0.0312,\n",
      "        -0.0005,  0.0725, -0.0005, -0.0511, -0.0076, -0.0789, -0.0281, -0.0232,\n",
      "        -0.0362, -0.0222, -0.0866, -0.0278,  0.0654, -0.0103,  0.0376, -0.0594,\n",
      "        -0.0234, -0.0041, -0.0202, -0.1031, -0.0094, -0.0028,  0.0026,  0.0234,\n",
      "        -0.0006,  0.0247, -0.0266, -0.0480, -0.0274,  0.0236, -0.1202,  0.0068,\n",
      "         0.0052,  0.0111,  0.0275, -0.0647,  0.0594,  0.0109,  0.1077, -0.0229,\n",
      "        -0.1101, -0.0484, -0.0866, -0.0450, -0.0464,  0.0025,  0.0148, -0.0315,\n",
      "        -0.1147,  0.0639, -0.0481,  0.0037,  0.0629,  0.0356, -0.0283, -0.0421,\n",
      "         0.0057, -0.0093,  0.0207, -0.0262,  0.1398,  0.0284, -0.1358,  0.0015,\n",
      "        -0.0642, -0.0075, -0.0834, -0.0212,  0.0367, -0.0407,  0.0336,  0.0396,\n",
      "         0.0209, -0.0701, -0.0084,  0.0275, -0.0645,  0.0347,  0.0176, -0.0360,\n",
      "        -0.0260,  0.0609, -0.0020, -0.0390,  0.1082,  0.0404,  0.0341, -0.0267,\n",
      "         0.0730, -0.0672, -0.0149, -0.0486, -0.0158,  0.0027,  0.0757,  0.0040,\n",
      "         0.0078,  0.0625, -0.0806,  0.0154,  0.0586, -0.0342, -0.1124,  0.0469,\n",
      "        -0.0436,  0.0435, -0.0309,  0.0674, -0.0214, -0.1200, -0.0687, -0.0824,\n",
      "        -0.0408, -0.0622,  0.0474, -0.0839, -0.0272,  0.0477, -0.0152, -0.0567,\n",
      "         0.0650, -0.0463, -0.0131,  0.0211, -0.0247, -0.0200, -0.0598,  0.0747,\n",
      "        -0.0090, -0.0043, -0.0132, -0.0947, -0.0065,  0.0119,  0.0375, -0.0045,\n",
      "        -0.0411, -0.0063,  0.0604,  0.0190, -0.0572, -0.0733, -0.0052,  0.0236,\n",
      "        -0.0529, -0.0551,  0.0298,  0.0483,  0.0484,  0.0546, -0.0232, -0.0300,\n",
      "         0.0504,  0.0075,  0.0707, -0.0121,  0.0172, -0.0379, -0.0032,  0.0104,\n",
      "         0.0262, -0.0676, -0.0777,  0.0215, -0.1397,  0.0124, -0.0374, -0.0038,\n",
      "        -0.1119,  0.0453, -0.0890, -0.0651]), '2.weight': tensor([[ 0.0812, -0.0343,  0.0307,  ...,  0.0219,  0.0972, -0.0541],\n",
      "        [ 0.0018, -0.0583,  0.0203,  ..., -0.0065,  0.0413,  0.0445],\n",
      "        [-0.1246,  0.0163,  0.0321,  ..., -0.2221, -0.0605,  0.0053],\n",
      "        ...,\n",
      "        [-0.0192, -0.0622, -0.0052,  ...,  0.0206, -0.0281, -0.0407],\n",
      "        [ 0.1481, -0.0522, -0.0141,  ...,  0.1026, -0.0140, -0.1191],\n",
      "        [ 0.0075, -0.0965, -0.0520,  ..., -0.1408,  0.1027, -0.0351]]), '2.bias': tensor([-0.0710, -0.0122, -0.1376,  0.1013, -0.0394, -0.0752,  0.1176, -0.0360,\n",
      "        -0.1468,  0.1103, -0.0970, -0.0267, -0.0194,  0.0851,  0.1512, -0.0446,\n",
      "        -0.1065, -0.1402, -0.1450,  0.0810, -0.0036, -0.0569,  0.1161,  0.0147,\n",
      "         0.1077,  0.0097,  0.1768,  0.1474, -0.0546,  0.0656,  0.0106, -0.0463,\n",
      "         0.0174, -0.0118,  0.0006, -0.0945,  0.0130,  0.0842,  0.1881, -0.0740,\n",
      "        -0.1222, -0.1375,  0.0535,  0.0611, -0.1339, -0.0241,  0.0524, -0.0970,\n",
      "         0.0664,  0.1325,  0.0191, -0.0552, -0.0558, -0.0369,  0.0271, -0.1530,\n",
      "         0.0322, -0.1792, -0.1092, -0.0384,  0.0548, -0.0446, -0.0856, -0.1720,\n",
      "        -0.0485,  0.1506,  0.0636,  0.0875,  0.0543,  0.0367, -0.0051,  0.0782,\n",
      "         0.1724,  0.0514, -0.0921,  0.0215,  0.0817, -0.1528,  0.1430,  0.0167,\n",
      "         0.2147, -0.0465,  0.0050,  0.0534,  0.0867, -0.1181, -0.0811, -0.0754,\n",
      "         0.1138,  0.0224,  0.1438, -0.0352, -0.0548,  0.0077,  0.1106, -0.1243,\n",
      "        -0.0407, -0.0416,  0.0268, -0.0772,  0.1073,  0.1782, -0.0269,  0.1544,\n",
      "        -0.0411,  0.1343, -0.0061, -0.0605,  0.0946,  0.0444, -0.1149,  0.0557,\n",
      "        -0.0241, -0.0905,  0.0467, -0.0981, -0.0512, -0.0650, -0.1180,  0.1468,\n",
      "        -0.0547,  0.0666, -0.0778, -0.0745, -0.0444,  0.0410, -0.1350, -0.0259,\n",
      "         0.0085, -0.0782,  0.0160,  0.0033, -0.0149, -0.0831,  0.0093,  0.1019,\n",
      "         0.1628, -0.0329,  0.0050, -0.1094, -0.0451, -0.1260, -0.0387,  0.0351,\n",
      "        -0.0935, -0.1012,  0.0082, -0.0925,  0.0034,  0.0615,  0.0926, -0.0853,\n",
      "        -0.0811, -0.0970, -0.2144,  0.0167, -0.1787, -0.0798, -0.1114, -0.0336,\n",
      "        -0.0350, -0.0643, -0.1241, -0.0394, -0.1120, -0.1195,  0.0395, -0.1094,\n",
      "        -0.0399, -0.1600,  0.0105, -0.1084, -0.1431, -0.0426,  0.0126,  0.0066,\n",
      "        -0.0188, -0.0749, -0.0499, -0.1042, -0.0524, -0.0985, -0.0244, -0.0042,\n",
      "        -0.1603, -0.0962, -0.1341, -0.0475, -0.0781,  0.2054, -0.0704, -0.1078,\n",
      "        -0.0004, -0.0692, -0.1450,  0.1402, -0.1517,  0.0456,  0.1874,  0.2172,\n",
      "        -0.1039, -0.0809,  0.0305, -0.0533, -0.1728, -0.0006,  0.1029, -0.1233,\n",
      "        -0.0127, -0.0691, -0.0801,  0.1104, -0.1443, -0.0763, -0.1323, -0.1460,\n",
      "         0.0201,  0.0460, -0.0086, -0.0271, -0.0117, -0.0166, -0.0796, -0.0181,\n",
      "        -0.0668,  0.0036,  0.1044, -0.0737,  0.1563,  0.0866,  0.1673, -0.0634,\n",
      "        -0.0518,  0.0360, -0.1210,  0.0342,  0.0109, -0.0854,  0.0323, -0.0836,\n",
      "        -0.1112, -0.0702,  0.1730,  0.0554,  0.0759, -0.1307,  0.0734,  0.1784,\n",
      "         0.2375, -0.1322,  0.0327, -0.1540,  0.0047, -0.0737,  0.0102, -0.0872,\n",
      "        -0.0741,  0.0633,  0.2588, -0.1565, -0.0508, -0.1181,  0.1218, -0.1050,\n",
      "        -0.0450,  0.0313, -0.1365, -0.0225,  0.0950, -0.0369, -0.1941, -0.0711,\n",
      "        -0.0177, -0.0308,  0.0158, -0.1191,  0.0419,  0.0783, -0.1347,  0.0892,\n",
      "        -0.1205, -0.0966, -0.0307,  0.1874,  0.1618, -0.1003, -0.0119,  0.0116,\n",
      "        -0.1011,  0.0911, -0.0587, -0.1075, -0.0053, -0.1103,  0.1583, -0.0638,\n",
      "        -0.0262, -0.0402,  0.0195, -0.0781, -0.0965,  0.0082,  0.0518,  0.0848,\n",
      "        -0.0399, -0.0892, -0.1204, -0.1594,  0.0099, -0.0003, -0.0708,  0.0978,\n",
      "        -0.0252, -0.1825,  0.0645,  0.0312, -0.1121,  0.1226,  0.1661, -0.0085,\n",
      "        -0.0889, -0.0729,  0.1585,  0.1561,  0.0685, -0.0214, -0.0775,  0.0221,\n",
      "         0.0455, -0.0522,  0.0726, -0.0270, -0.0810,  0.1193, -0.0340, -0.0888,\n",
      "        -0.0996, -0.0433, -0.1148, -0.0378,  0.0244, -0.1145, -0.1385,  0.0057,\n",
      "        -0.0120,  0.0884, -0.0213, -0.1621,  0.0258, -0.0026,  0.0578, -0.0796,\n",
      "        -0.1057, -0.1473, -0.0926, -0.1352,  0.0704, -0.0236,  0.1298, -0.0778,\n",
      "        -0.0624,  0.1078, -0.1316,  0.0149, -0.0438, -0.1641,  0.0093,  0.0978,\n",
      "        -0.0918, -0.0329,  0.0204,  0.0502, -0.0690, -0.0415, -0.1203,  0.0209,\n",
      "        -0.0579, -0.0223,  0.1758, -0.0839,  0.0319, -0.0008, -0.0575, -0.0775,\n",
      "        -0.1658, -0.0282,  0.1287, -0.0724,  0.1054, -0.0090,  0.0471, -0.1259,\n",
      "         0.0115,  0.0250, -0.1572,  0.0270,  0.0670, -0.1248, -0.1223, -0.0319,\n",
      "         0.1363, -0.1027, -0.0777, -0.0852, -0.0831, -0.0202, -0.1348, -0.0661,\n",
      "         0.1349, -0.0572,  0.2420, -0.0423,  0.0789, -0.0335,  0.0988, -0.0064,\n",
      "         0.1181, -0.1070,  0.0201, -0.0294, -0.1616,  0.0317, -0.0302,  0.1416,\n",
      "        -0.0865,  0.1880,  0.2246, -0.0829, -0.0916, -0.0905, -0.1508, -0.0227,\n",
      "        -0.1153,  0.0732, -0.0157,  0.0052, -0.1125,  0.0321, -0.0380, -0.0319,\n",
      "         0.1102,  0.0509,  0.1970, -0.0415, -0.0705,  0.0665, -0.0948, -0.1388,\n",
      "        -0.0290, -0.1171, -0.1241, -0.0431,  0.0740, -0.0508, -0.0520, -0.0050,\n",
      "        -0.0844, -0.0374, -0.1006,  0.2279, -0.0530, -0.1121,  0.0321,  0.1167,\n",
      "        -0.0579, -0.1133,  0.1214,  0.0119,  0.1842,  0.1218,  0.1040,  0.0731,\n",
      "        -0.0814,  0.0489, -0.0447,  0.1577,  0.1222, -0.0976, -0.0473,  0.0696,\n",
      "        -0.0643,  0.0684, -0.0619,  0.0138,  0.1846, -0.0808,  0.1277,  0.0978,\n",
      "         0.2068, -0.0089, -0.0463, -0.1179, -0.0884,  0.0578, -0.0037,  0.1469,\n",
      "         0.0379, -0.0544,  0.1151, -0.0027]), '4.weight': tensor([[-0.0915,  0.1062, -0.0531,  ..., -0.0611,  0.0214, -0.0740],\n",
      "        [-0.0386,  0.0547,  0.0521,  ...,  0.0303, -0.1696, -0.0570],\n",
      "        [-0.1332, -0.0213,  0.1060,  ..., -0.0025, -0.1568,  0.0603],\n",
      "        ...,\n",
      "        [ 0.0462, -0.2228,  0.0954,  ..., -0.0069, -0.0905, -0.1133],\n",
      "        [-0.1079,  0.0445, -0.2964,  ...,  0.0265,  0.0501,  0.0982],\n",
      "        [ 0.0519, -0.0531, -0.0812,  ...,  0.0045,  0.0299, -0.0818]]), '4.bias': tensor([-0.0056, -0.1399,  0.0318, -0.0792, -0.0319, -0.0118, -0.0413, -0.0827,\n",
      "         0.2887,  0.0774])})\n",
      "Final Loss: 0.0183\n",
      "Accuracy: 97.74 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28*28  # Image size in pixels\n",
    "hidden_size = 500  # Number of neurons in the hidden layer\n",
    "num_classes = 10  # Number of classes to recognize (10 digits)\n",
    "n_epochs = 5  # Number of epochs\n",
    "batch_size = 32  # Mini-batch size of input data\n",
    "lr = 0.001  # Learning rate\n",
    "\n",
    "# Download dataset\n",
    "mnist_trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Init device as usual\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Standard \"training step\" function\n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step\n",
    "\n",
    "# Model definition\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        loss = train_step(images, labels)\n",
    "        train_losses.append(loss)\n",
    "    print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss:.4f}')\n",
    "\n",
    "# Print model state dict and loss\n",
    "print(model.state_dict())\n",
    "print(f'Final Loss: {loss:.4f}')\n",
    "\n",
    "# Evaluate model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Save model\n",
    "torch.save(model, 'mnist_full.pt')\n",
    "model = torch.load('mnist_full.pt')\n",
    "model.eval()\n",
    "\n",
    "# Visualize the model's performance on test data\n",
    "def plot_images(images, labels, preds):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'True: {labels[i]}\\nPred: {preds[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some test data\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = next(data_iter)\n",
    "images = images.reshape(-1, 28*28).to(device)\n",
    "outputs = model(images)\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "# Plot the images\n",
    "plot_images(images.cpu(), labels.cpu(), preds.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39bff24-83d0-45f2-874c-ce08e488ea61",
   "metadata": {},
   "source": [
    "Brilliant! We got\n",
    "\n",
    "```\n",
    "Final Loss: 0.0183\n",
    "Accuracy: 97.74 %\n",
    "```\n",
    "\n",
    "How we achieved that?\n",
    "Basically, by applying all the things we studied in the previous lessons.\n",
    "\n",
    "---\n",
    "\n",
    "1. We have increased the number of training epochs from 2 to 5, it is not a surprise that it helps to get more accurate model.\n",
    "2. We are aldo increased the number of model layers. The`hidden_size` stayed the same as 500 but added, we just added an additional layer.\n",
    "     ```python\n",
    "     model = nn.Sequential(\n",
    "         nn.Linear(input_size, hidden_size),\n",
    "         nn.ReLU(),\n",
    "         nn.Linear(hidden_size, hidden_size),\n",
    "         nn.ReLU(),\n",
    "         nn.Linear(hidden_size, num_classes)\n",
    "     )\n",
    "     ```\n",
    "\n",
    "3. We are also increased `batch_size` from 4 to 32. Larger batches might lead to more stable gradient estimates and faster convergence. But also it is a trade-off with computational resources and training time. But, it trained relatively fast on M1 Pro cpu, so...\n",
    "\n",
    "4. We are also changed learning rate (`lr`) by decreasing it from 0.01 to 0.001. It allows the model to make more precise updates to the weights.\n",
    "\n",
    "5. And finany, for visualizing model performace we are used  `matplotlib`. We mapped the original test images, their true labels, and the predicted labels from the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
